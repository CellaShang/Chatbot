{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e-PoEm-Z5grh","executionInfo":{"status":"ok","timestamp":1753049623055,"user_tz":240,"elapsed":16350,"user":{"displayName":"Yue Shang","userId":"00268558011417117003"}},"outputId":"818eb3b8-65c0-4191-c0a6-311d05dbf81c"},"id":"e-PoEm-Z5grh","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":6,"id":"3808f52f-4d52-49d2-821f-93f31244d55b","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"3808f52f-4d52-49d2-821f-93f31244d55b","executionInfo":{"status":"error","timestamp":1753050474456,"user_tz":240,"elapsed":111043,"user":{"displayName":"Yue Shang","userId":"00268558011417117003"}},"outputId":"8ea8f7c6-8040-49bb-86ec-ec25b1bc9baa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training and evaluating with feature set: TF-IDF\n","  Fold 1: Accuracy = 0.9600, ROC-AUC = 0.9890\n","  Fold 2: Accuracy = 0.9500, ROC-AUC = 0.9942\n","  Fold 3: Accuracy = 0.9300, ROC-AUC = 0.9949\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-6-1059883824.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Initialize XGBoost classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mlogloss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1597\u001b[0m             )\n\u001b[1;32m   1598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1600\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             _check_call(\n\u001b[0;32m-> 2101\u001b[0;31m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2102\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m                 )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, roc_auc_score\n","from sklearn.preprocessing import label_binarize\n","import xgboost as xgb\n","DPPpath = '/content/drive/My Drive/Colab/AS4/STEP2-feature_Engineering/'\n","# Load preprocessed features\n","df_tfidf = pd.read_pickle(DPPpath + 'features_tfidf.pkl')\n","df_bow = pd.read_pickle(DPPpath + 'features_bow.pkl')\n","df_ngram = pd.read_pickle(DPPpath + 'features_ngram2.pkl')\n","df_lda = pd.read_pickle(DPPpath + 'features_lda.pkl')\n","\n","# Prepare data\n","labels = df_tfidf['label']\n","numeric_labels = df_tfidf['label_num'].values\n","classes = np.unique(numeric_labels)\n","y_binarized = label_binarize(numeric_labels, classes=classes)\n","\n","# Feature matrices (drop label columns)\n","X_tfidf = df_tfidf.drop(['label', 'label_num'], axis=1).values\n","X_bow = df_bow.drop(['label', 'label_num'], axis=1).values\n","X_ngram = df_ngram.drop(['label', 'label_num'], axis=1).values\n","X_lda = df_lda.drop(['label', 'label_num'], axis=1).values\n","\n","# Combine features function\n","def combine_features(*arrays):\n","    return np.hstack(arrays)\n","\n","# Dictionary of feature sets (include individual and combinations)\n","feature_sets = {\n","    'TF-IDF': X_tfidf,\n","    'BoW': X_bow,\n","    'N-grams': X_ngram,\n","    'LDA': X_lda,\n","    'TF-IDF + BoW': combine_features(X_tfidf, X_bow),\n","    'TF-IDF + N-grams': combine_features(X_tfidf, X_ngram),\n","    'TF-IDF + LDA': combine_features(X_tfidf, X_lda),\n","    'BoW + N-grams': combine_features(X_bow, X_ngram),\n","    'BoW + LDA': combine_features(X_bow, X_lda),\n","    'N-grams + LDA': combine_features(X_ngram, X_lda),\n","    'TF-IDF + BoW + N-grams': combine_features(X_tfidf, X_bow, X_ngram),\n","    'TF-IDF + BoW + LDA': combine_features(X_tfidf, X_bow, X_lda),\n","    'TF-IDF + N-grams + LDA': combine_features(X_tfidf, X_ngram, X_lda),\n","    'BoW + N-grams + LDA': combine_features(X_bow, X_ngram, X_lda),\n","    'All Combined': combine_features(X_tfidf, X_bow, X_ngram, X_lda),\n","}\n","\n","# Set up 10-fold cross-validation\n","kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","results = {}\n","\n","for name, X in feature_sets.items():\n","    accuracies = []\n","    roc_aucs = []\n","\n","    print(f\"Training and evaluating with feature set: {name}\")\n","    for fold, (train_index, test_index) in enumerate(kf.split(X, numeric_labels), 1):\n","        X_train, X_test = X[train_index], X[test_index]\n","        y_train, y_test = numeric_labels[train_index], numeric_labels[test_index]\n","        y_test_binarized = y_binarized[test_index]\n","\n","        # Initialize XGBoost classifier\n","        model = xgb.XGBClassifier(eval_metric='mlogloss', random_state=42)\n","        model.fit(X_train, y_train)\n","\n","        # Predict\n","        y_pred = model.predict(X_test)\n","        y_proba = model.predict_proba(X_test)\n","\n","        # Metrics\n","        acc = accuracy_score(y_test, y_pred)\n","        roc_auc = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n","\n","        accuracies.append(acc)\n","        roc_aucs.append(roc_auc)\n","\n","        print(f\"  Fold {fold}: Accuracy = {acc:.4f}, ROC-AUC = {roc_auc:.4f}\")\n","\n","    avg_acc = np.mean(accuracies)\n","    avg_roc = np.mean(roc_aucs)\n","    results[name] = (avg_acc, avg_roc)\n","    print(f\"Average Accuracy: {avg_acc:.4f}, Average ROC-AUC: {avg_roc:.4f}\\n\")\n","\n","# Summary of all feature sets\n","print(\"\\nSummary of Results:\")\n","print(f\"{'Feature Set':<30} {'Accuracy':<10} {'ROC-AUC':<10}\")\n","for key, (acc, roc) in results.items():\n","    print(f\"{key:<30} {acc:<10.4f} {roc:<10.4f}\")\n","\n","# Select the best feature set by accuracy\n","best_feature_set = max(results.items(), key=lambda x: x[1][0])\n","best_name, (best_acc, best_roc) = best_feature_set\n","\n","print(\"\\n=== Best Feature Set ===\")\n","print(f\"Feature Set: {best_name}\")\n","print(f\"Accuracy: {best_acc:.4f}\")\n","print(f\"ROC-AUC: {best_roc:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"0f162026-a64c-45d4-9d6c-44848f98af17","metadata":{"id":"0f162026-a64c-45d4-9d6c-44848f98af17","outputId":"c0629a99-772f-4d18-856b-f6efcf673c90"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","=== Classification Report (BoW + N-grams + LDA, 80/20 split) ===\n","                                           precision    recall  f1-score   support\n","\n","                 gene expression analysis       0.98      1.00      0.99        40\n","    sequence classification and alignment       0.90      0.90      0.90        40\n","protein structure and function prediction       0.93      0.93      0.93        40\n","                biological image analysis       1.00      0.88      0.93        40\n","               disease outcome prediction       0.89      0.97      0.93        40\n","\n","                                 accuracy                           0.94       200\n","                                macro avg       0.94      0.93      0.93       200\n","                             weighted avg       0.94      0.94      0.93       200\n","\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","\n","# Use best-performing feature set\n","X_best = feature_sets['BoW + N-grams + LDA']\n","y = numeric_labels\n","target_names = labels.unique()\n","\n","# Split data: 80% train, 20% test\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_best, y, test_size=0.2, stratify=y, random_state=42\n",")\n","\n","# Train XGBoost\n","model = xgb.XGBClassifier(eval_metric='mlogloss', random_state=42)\n","model.fit(X_train, y_train)\n","\n","# Predict on test set\n","y_pred = model.predict(X_test)\n","\n","# Classification Report\n","print(\"\\n=== Classification Report (BoW + N-grams + LDA, 80/20 split) ===\")\n","print(classification_report(y_test, y_pred, target_names=target_names))\n"]},{"cell_type":"code","execution_count":null,"id":"4f582937-77d6-4e9e-9e5c-e4b90f1082f2","metadata":{"id":"4f582937-77d6-4e9e-9e5c-e4b90f1082f2","outputId":"f8e5944f-ab56-45dc-a292-c661e73b1e82"},"outputs":[{"name":"stdout","output_type":"stream","text":["XGBoost results successfully saved to 'xgboost_results.pkl'.\n"]}],"source":["# Save results to a file for later comparison\n","import pickle\n","import os\n","\n","xgb_file = \"xgboost_results.pkl\"\n","with open(xgb_file, \"wb\") as f:\n","    pickle.dump(results, f)\n","\n","# Confirm file was saved\n","if os.path.exists(xgb_file):\n","    print(f\"XGBoost results successfully saved to '{xgb_file}'.\")\n","else:\n","    print(f\"Failed to save XGBoost results.\")\n"]},{"cell_type":"code","execution_count":null,"id":"f836564a-95ab-49ba-ae3e-b67dcd6414ea","metadata":{"id":"f836564a-95ab-49ba-ae3e-b67dcd6414ea"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}